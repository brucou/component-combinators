SOURCE OF TRUTH IN BLOG

# Componentization
## Abstractions against complexity
We have previously seen that a reactive system can be described by equations involving a reactive function `f` such that `actions = f(state, events)`. In theory, the function `f` is as complex as the specification of the reactive system to implement. In practice, it is often much more so, as dictated by the particular implementation choices made.

Complexity resists to a uniformally useful definition. However, it is generally accepted that there is a component of complexity which cannot be reduced by any particular technique. <em>How many systems do we have? In what convoluted manner are they connected? What the requirement for operating these systems? How many parameters or subtasks are necessary to specify a task?</em>. That complexity increases every year, as the trend is into interconnecting more and more systens to satisfy ever astringent user requirements to do more things in less time. To reuse a commonly used term, we will call this the essential complexity of the system under specification.

Oddly enough, at the same time, on a subjective level, things that were complex last year are less complex now. That subjective but very real component of complexity relates the number of things that cause problems to our ability to deal with them. Our ability to deal with them goes up as we develop better languages, tools, interfaces, architecture, infrastracture, etc. and are able to do more with less. We would define this component of complexity as accidental complexity, and as being the complexity that an implementation approach adds to the essential complexity corresponding to the specification of a system.

As a side note, a user interface itself is precisely an attempt at shielding the user from the complexity of underlying systems so he can focus on the domain at hand and the tasks it encompasses. In other words, the user interface **abstracts** out the underlying system layer. As a matter of fact, most advances against accidental complexity (in **any** field) are made by better and/or more powerful abstractions.

We can list a short range of abstractions taking aim at specific sources of complexity, at the system implementation level : 

- domain : domain modeling
- implementation : domain-specific language
- persistence : databases
- asynchrony : streams (!!)
- memory : garbage collector, constructors
- testing : model-based testing 
- design : componentization
- programming paradigm : declarative programming (including functional programming, dataflow programming, logic programming)  

In the current state of my knowledge, I believe that the most effective levers in mastering complexity are domain modelling, domain-specific languages, and components, glued together by means of declarative programming. 

We will detail in what follows what makes componentization an abstraction, the benefits to be expected, but also the costs and barriers associated, concluding that componentization is a strategic decision to be pondered over.

We will then detail what constitutes a component framework, taking as example the component framework we are proposing to implement reactive systems. We move on to give pointers on what constitutes a successful componentization.

## Componentization as an abstraction
The major goal in software construction is to build software that are robust (i.e. performs correctly and does not crash even in unforeseen cases), flexible (i.e. can be used in many seemingly different applications), extensible (i.e. can be extended with minimal if not no modification of existing code), easy to maintain (i.e. to modify to improve performance or fix "bugs"). The main tool of the trade of software developers can be summarized in one word: abstraction.

The abstraction process involves several steps:

- Eliminate all unnecessary details and get to the essential elements of the problem and express them clearly and concisely as invariants.
- Encapsulate that which vary and express them as variants.  The variants of abstractly equivalent behaviors are grouped into appropriate taxonomy of abstract classes and subclasses.
- Define the dynamics of the system in terms of the  interplay between the invariants and the variants.  Sometime the invariants/variants interplays can be straightforward, but more than often they can be subtle like the case when an invariant can be expressed in terms of many variants.

The effort spent in identifying and delineating the invariants from the variants usually leads to the construction of what is called a component framework system where the invariants form the framework and the variants constitute the components.

![Component framework](https://www.clear.rice.edu/comp310/JavaResources/frameworks/frameworks.png)

Hence, in essence, component-frameworks break the system down into variant "components" that represent abstract processing that the system supports. These components are generally thought of as "pluggable" in the sense that the system can be configured with a set of components to accomplish a particular task or set of tasks.   In many systems, the components can dynamically swapped in and out.   The framework, on the other hand, is the invariant "superstructure" that manages the components, providing services to each component that, when combined with the services/behaviors supplied by that component, create the net behavior defined by that component in that framework.    The framework has the effect of decoupling or isolating the components from each other since it the component interactions are handled by the framework in a manner that is opaque to the components.

## Benefits
As previously mentioned, the benefits are : 

- productivity, coming from a component framework design targeted at reuse, and composability
- readability
  - when a given component addresses a specific concern, which is not addressed elsewhere (i.e. achieving separation of concerns), the reactive system is easier to reason about
- maintainability
  - components can be replaced easily, by a better or equivalent version  
- reliability
  - in the measure that components and the component framework are properly tested and reliable, the surface area on which bugs can attach themselves is considerably lower

## Barriers to reuse
Despite all the potential of componentization, significant barriers to component reuse have been observed :

- The business model is unclear
- It costs a client too much to understand and use a component
- Components have conflicting world views

Componentization is hence a strategic decision which will depend on a componay's strategic context.

### Unclear business model
Design is expensive, and reusable designs are very expensive. It costs between ½ and 2 times as much to build a module with a clean interface that is well-designed for your system as to just write some code, depending on how lucky you are. But a reusable component costs 3 to 5 times as much as a good module.

The extra money pays for:

- generality
  - A reusable module must meet the needs of a fairly wide range of ‘foreign’ clients, not just of people working on the same project. Figuring out what those needs are is hard, and designing an implementation that can meet them efficiently enough is often hard as well.
- simplicity
  - Foreign clients must be able to understand the interface to a module fairly easily, or it’s no use to them.
- customization
  - To make the module general enough, it probably must be customizable, either with some well-chosen parameters or with some kind of programmability
- testing
  - Foreign clients have higher expectations for the quality of a module, and they use it in more different ways. The generality and customization must be tested as well
- documentation
  - Foreign clients need more documentation, since they can’t come over to your office
- stability
  - Foreign clients are not tied to the release cycle of a system. For them, a module’s behaviour must remain unchanged (or upward compatible) for years, probably for the lifetime of their system

Designing for all those aspects is an investment that must be recouped in the future. Apart from very large companies, such as google or facebook, and some popular open-source projects, or large software development firms, the business case for such investment is not clear.

### Cost to understand
To use a component, the client must understand its behaviour. This is not just the functional specification, but also the resource consumption, the exceptions it raises, its customization facilities, its bugs, and what workarounds to use when it doesn’t behave as expected or desired.
 
Furthermore, because the written spec is often quite inadequate, there is uncertainty about the cost to discover the things that aren’t in the spec, and about the cost to deal with the surprises that turn up. If the module has been around for a while and has many satisfied users, these risks are of course smaller, but it’s difficult to reach this happy state.

### Conflicting world views
Components are tied to a component framework, which defines its interface and lifecycle, by thus limiting the scope of their reuse out of that framework. Adapters and bridges can be built to palliate that situation. However that is not always possible or practical.

As a matter of fact, Angular2 components cannot be reused out of Angular2, React components can be adapted to React-like frameworks but it takes some efforts, etc. Web components, which are supposed to be a common standard, allowing reuse in all browsers, have been arriving for many years, and are still a work in progress, illustrating the difficulty of designing simultaneously for many targets.

### Componentization is a strategic decision
The option of componentization to implement a reactive system, must, like any architectural decision, be weighted in the context of the specific implementing company/project/team. A start-up who will anyways trash its minimum viable product the next year after receiving funding  might prefer avoid going through the trouble, while companies which are constantly developing software might want to invest in carefully designed components.

**TODO** put in bibliography somewhere
[Why Software Reuse has Failed and How to Make It Work for You](https://www.dre.vanderbilt.edu/~schmidt/reuse-lessons.html)

## Component framework
A component framework or platform provides both a systematic method to construct components, possibly from other components (namely dealing with interfacing, binding and interactions between components), and a systematic interface between component and the component framework, by which components can be introspected, instantiated, executed, destroyed (namely dealing with component lifecycle)[^A classification framework for software component models].

The first figure shows a classification framework for software component models, emphasizing the miscellaneous responsibilities of a component model. We will not mention here the third point (extra-functional properties). 

![Classification framework for software component models](https://i.imgur.com/9yziyvB.png)

The second figure illustrates construction mechanisms linking components to each other and to the component framework. 

![Component framework](https://i.imgur.com/mLozPJ4.png)

The third figure illustrates the two key ways to interface components : operational-based interface, or port-based interface.

![Interface specification](https://i.imgur.com/t84fq4c.png)

### Proposed component framework
We have seen previously that to implement a reactive system we need :

- a reactive function `f` linking actions to events
- an interface with the systems through which actions intended by the user must be performed
- an interface by which the reactive system receives its events

Our component framework will be inspired by `cyclejs` framework. A component will be a procedure `f :: Sources -> Settings -> Sinks`, where :

- `Sources` contains any necessary accessor/factory methods to the internal state of the framework and relevant events
- `Settings` represents the parameterization concern of the component behaviour
- `Sinks` holds the computed action representations in response to incoming events

Note that `f` here is not in general a pure function, as typically `f` is accessing the external world to read events from it. We will still call `f` the reactive function, by abuse of language. It would be easy to write `f = compose(g, h)` where `h :: Sources -> Settings -> Events` and `g :: Events -> Settings -> Sinks`, so that `g` is a pure function. We however follow `cyclejs` choice here and accept an impure reactive function, for reasons we will detail thereafter. 

The component framework exposes an interface to its components by which it receives the actions to be perfomed : `Sinks :: HashMap<SinkName, Sink>`, is to be matched with `Drivers :: HashMap<SinkName, Driver>`, where a `Driver :: Sink -> Source` takes responsibility for the **execution** of actions passed through the **matching** sink, and passing up the eventual results of such actions as an event into the reactive system.

The component framework also exposes the interface which the reactive system receives its events : `Sources :: HashMap<SourceName, Source>`, where `Source` is anything presenting an interface to access **events** and **state** from/of external systems of interest. `Source` can, for instance, be a parameterizable event factory (events obtained from DOM listeners, etc.). `SourceName` is a moniker uniquely referencing the corresponding source of events.

The component framework connects together identical `SourceName` and `SinkName`, so that a driver corresponding to a given `SinkName` will output the result of the actions it executes as events with the same moniker as a `SourceName`.

In the context of this component framework, component composition is simply function composition, with message-passing/dataflow through streams and a port-based interface emulated by the monikers `SinkName`, `SourceName`.

We will review in what follows parallel composition, sequential composition, parametricity and genericity, all of which being concerns incorporated into what we term component combinators.

#### Parallel composition
Parallel composition in our context is based on expressing the reactive function `f` as the combination of functions, each of which captures a smaller and ideally isolated part of the overall `f`'s complexity. 

The bet is that :

- the smaller functions will lead to lower complexity, 
- that complexity will be low enough to be addressed satisfactorily at the smaller function level, 
- `f` can be recombined in a systematic way without loss in specification from the smaller functions
- it will be possible to encapsulate a large class of reactive subsystems into reusable generic components, which can then be parameterized to reflect the targeted reactive subsystem at hand. 

In short, we want a `combine :: Array<Component> -> Component`, where :

- `f`, the reactive function is a `Component`
- `f` can be obtained by applying `combine` to other reactive functions 
	- `f = combine([f1, f2, f3...])`

Note that :

- the `combine` function can take any extra arguments, in which case, by uncurrying, it is always possible to come back the canonical `combine` form shown previously.
- As any component used to derive another component can itself have been derived, parallel composition naturally leads to the manipulation of component trees
	- `f = combine([f1, f2...])`
	- `f = combine([combine([f1.1, f1.2, f1.3...]), combine([f2.1, f2.2, f2.3...])...])`
	- etc.

There are usually many ways to perform that decomposition. The idea in every case is to reach functions `fm.n...` whose complexity is easily manageable. If we understand that part of complexity of such `f...` emanates from the top-level `f`, while another part stems from the interaction of `f...`s with the larger reactive system, we see that there is a sweet spot where the function is 'small' enough to be manageable but not too small so it has to be coupled with many other `f...`s to achieve a given functionality (coupling increases complexity).

#### Sequential composition
**TODO**
- adapting the outputs
	- none for now, just in `ListOf` we have a `sinkname` mapping function, maybe that could be a setting in every combinator, i.e. another option for m?? but then I would need the symetric feature for mapping inputs, and then inputs and mapped inputs are both in settings, so do I remove the inputs and keep only the mapped inputs etc. to think about, it is not so simple, both case could be valid, and having both increase complexity and surface of API
**TODO**

We want `combine :: Array<Component> -> Component`, where :

- combine([f]) = f
- combine([f, g]) 
  - only defined when f and g have at least one matching output/input
  - connect input to output TODO show some diagram - ah already did
  - if not defined returns empty component, the component who does nothing OR ERROR??

#### Genericity, parametricity and reuse
At the core of reusability of components is the ability to design components implementing a behaviour which is generic enough to cover a large set of contexts, and parameterizable enough to be customized at design-time or run-time without modification.

In this effort, as previously introduced, we will address the parameterization concern with a specific parameter (`:: Settings`) passed to the reusable component factories or combinators. For instance a `CheckBox` component implementing the generic reactive system made of a checkbox which when clicked emits an action including its checked/unchecked state,  could be written to be parameterized in appearance/style (allowing to customize the checkbox background for example).
 
#### Component combinators
A component combinator is a function of the type `Combinator :: Settings -> Array<Component> -> Component`. The signator is basically the formerly presented `combine` signature to which `Settings` have been added to allow to parameterize the behaviour of the combinator.

Those combinators are themselves specialization of a generic combinator, here called `m`, with `m :: CombinatorSpecs -> Settings -> Array<Component> -> Component`, which can also be written `m :: CombinatorSpecs -> Combinator`. That is, one can see `m` both as a combinator factory, or a component factory.

We have so far implemented a list of combinators which allow to realize the following composition :

- merge reactive functions
- switch reactive functions according to events
- recursively switching reactive functions according to route (i.e. nested routing)
- merge a list of reactive function based on a template and incoming array
- extend a reactive function to process additional events or add extra parameterization
- build a set of reactive functions into a state machine

We have not so far implemented specific combinators for sequential composition.

#### Example
give an example of one reactive system with a reactive function within the framework. And then the same reactive function broken down in two
no code, use shapes and colors to represent sources and actions, maybe imagine an animation to represent the live system? This MUST be taken from angular2 example

### Characteristics of a good decomposition
A good decomposition should :

- decide on the ideal granularity of the decomposition
- identify generic reusable components
- exhibit high cohesion and loose coupling

#### Granularity of decomposition
As previously seen, breaking down the system in loosely coupled parts results in the individual parts having lower complexity. The right level of granularity comes from the tradeoff between fine-grain componentization (large number of small and relatively simple components) and coarse grain componentization (small number of large and relatively complex components). On the one hand, finer grain components are simpler to implement. On the other hand, decomposition into a large number of fine-grain components makes the interactions among components voluminous. In that case, the corresponding increase in complexity may overweight the decrease in complexity experienced in the individual components, nullifying the benefits of componentization.

Additionally there might non-functional costs to decomposition which becomes non-neglectable at a fine-grain level (performance, resource consumption, etc.). Hence the optimal granularity of a decomposition must be assessed on a case-by-case basis.

Hierarchical decomposition (where components are themselves composed from other components, termed as children components) helps alleviate somewhat issues from fine-grain decomposition, by containing the increase in interaction between components (interaction is restricted to the scope of the parent component). As we saw before, this hierarchical decomposition gives birth to a component tree, where each parent component (node) is connected to its children (subtrees).

A system with hierarchical modularity can be viewed at different granularities, from coarser grain at the top of the hierarchy to a finer grain at the bottom. The goal is to constrain the interacting modules at each level to an understandable number while avoiding constraints linked to the total number of components.

System design is top-down: first the coarse-grain modularity is established, and at each successive phase the next level of hierarchy is established by decomposition of the modules at the next higher level. System implementation, on the other hand, is bottom-up: Only the modules at the leaves of a hierarchy are actually implemented, while each module above is integrated from existing modules below, starting at the bottom.

**TODO** show a generic graph with hierarchical components, and show that only the leaves have to be implemented. SAME example of angular2 differently commentd

#### Generic components vs. ad-hoc components
In the frame of reactive systems, two main drivers lead decomposition :

- reusing already existing components
  - in the context of reactive system, this mostly involves reusing common presentational/behavioural functionalities : tabbed groups, cards, breadcrumbs, etc. An existing library of reusable components can be leveraged to that effect. Those components however have to be customizable per the actions triggered by user events, or offer an interface decoupled from such actions, i.e. decoupled from the domain at hand.
- separating concerns
  - typically a graphical application will have events belonging to a specific region of the screen. An obvious divide-and-conquer strategy is to break down the application in such independent regions and assign a component to each of those. A component could for instance handle the navigation concern of the application, while another might handle displaying a domain object and possible interactions with that object, with yet another handling notifications from external systems to the application.

It is in addition worthy to identify domain-specific components, should they arise from the application implementation. This might be for instance in the case of a trading application, components which display value of a stock in real-time. 

**TODO** show a UI like angular2 for example, and then take different regions of the UI, and mark them : they will correspond to independent components (exclusive responsibility for handling events). SAME example of angular2 differently commentd
 
### TODO
a lot of things following to remove or put elsewhere:
-Component adaptation goes to `m` rationale or documentation

also refactor `m` code to make more apparent the aspect weaving
cf. On Interplay between separation of concerns and genericity, and ART language example

put all the following in a detailed step-by-step example

## Example of specs as sequence [(event,action)]
Counter : input box = counter in DB, click -> increase counter and save in db
2 counters for 2 dbs, click increase both counters
- `actions = f(state, events)`
- `State :: (DB1_STATE, DB2_STATE)`
- `Events :: ButtonClick1 | ButtonClick2`
- f(state, click) -> Increase Db1State state, Increase Db2State state (2 actions)
	- f1 (DB1_STATE, ButtonClick1 )
	- f2(DB2_STATE, ButtonClick2)
	- f = f1+f2

So State -> focus -> lens
So Events -> choose -> prism

TODO : explain that better
INSERT example

SHOW how thermite framework, elm framework, cycle can be derived as variation on the reactive formulation

## thoughts on constant and variable part of the state
State may further be segmented into :

- constants : constants are passed through use of a segregated `settings` variable
- variable : the variable part of the state may be passed through what is coined as **behaviours** in Conall Eliott's FRP.

State is passed down the component hierarchy via `InjectSources`, `InjectSourcesAndSettings` combinators

**TODO** : clarify the whole/part relation of states. States here is a stream, so that will be a stream which is a tree of substates. It all comes down to the derivation relation : focus (sub state, i.e. lens) or extend (new state type, i.e. prism)
**TODO** :  actually the settings that I pass is because of the necessity to customize generic components (generic UI components for example). Are they also representing constant state?? To think about

## Recombining phase
`actions` is recombined through `actions1`, `actions1.1`, etc. and the help of `combine` operators.

In the particular case of the 'update screen' action, recombination is performed based on insertion markers, called slots (following the web component terminology). Those slots are marked via the `InSlot` combinator.

## Summary
In summary, reactive systems can be specified by means of a reactive function associating inputs to actions. That reactive function can be obtained by composition of reactive functions from smaller reactive systems. 

A good decomposition or factoring is one : 

- which ensures for each subsystem a reduction in complexity
(simpler specifications, smaller size of the reactive system, few interactions with other subsystems i.e. intercomponent dependency)
- which can be reassembled in a way that is easy to reason about and trace
- can be parameterized without modification (open-closed principle), so futures changes in the overall reactive system have a higher change to result mainly in changes in parameterization of subsystems.
- highly cohesive, loosely coupled to ensure adaptability : 80% of software engineering deals with maintaining or releasing new versions. The cost of redesigning each of such adoptable components (or replacing by a better component) must be minimized.

In our reactive system, `cyclejs` context, for component construction and interfacing, functions are used, exposing a fixed interface, differentiating parameterization concern and dataflow concern in their inputs; a port metaphor is used for component sequential composition ; combinators are used for parallel composition. Component lifecycle is handled by the framework which by means of <em>start</em> and <em>stop</em> functionalities.
  
  TODO : talk about the combinator roles in the construction of component!!! talk about stream and dataflow that is an important part of the interface specification
  TODO : put the start and stop in the part where I talk about component framework

## Bibliography
[Reducing Complexity in Software & Systems](https://www.sei.cmu.edu/podcasts/podcast_episode.cfm?episodeid=443886)

[Software Component Models - Component Life Cycle](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.450.9230&rep=rep1&type=pdf)
> The minimum criteria correspond to the definition of component models given in the introduction and in Section 2:
  1) A component model includes a component definition;
  2) A component model provides rules for component
  interoperability;
  3) Component functional properties are unambiguously specified by component interface;
  4) A component interface is used in the interoperability mechanisms;
  5) A component is an executable piece of software and
  the component model either directly specifies its
  form or unambiguously relates to it via interface
  and interoperability specification.

[Component Based Systems - 2011](http://www.win.tue.nl/~johanl/educ/2II45/ADS.09.CBSE.pdf)

[Component-Framework Systems](https://www.clear.rice.edu/comp310/JavaResources/frameworks)

[A Generic Component Framework for System Modeling](https://link.springer.com/content/pdf/10.1007/3-540-45923-5_3.pdf)
> In this sense, given a generic modeling technique with model specifications in the sense of 2.1, we are now able to define our generic component concept. A component specification, in short component, `COMP = (IMP, EXP, BOD, imp, exp)` consists of model specifications and connections:
> 
> – IMP, called import interface,
> – EXP, called export interface,
> – BOD, called body,
> – imp: IMP → BOD, called import connection,
> – exp: EXP → BOD, called export connection.

[A classification framework for software component models](https://pdfs.semanticscholar.org/04ab/304cd8102fdbecd6a41cde9a934e1567b1b3.pdf)

[Software Components: Only The Giants Survive]()70-SoftwareComponents and reusability - challenges
